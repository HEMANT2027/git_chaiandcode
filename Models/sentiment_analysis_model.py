# -*- coding: utf-8 -*-
"""Untitled36.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mKksFi97jTiBmdofVxqsplMXEJS8tZyD
"""

!huggingface-cli login

from transformers import pipeline
import torch
import re
import gc
import time
pipe = pipeline("text-generation", model="google/gemma-3-1b-it",do_sample=False, top_k=1)

#hinglish----->english
def translation(text):
  messages1 = [
      [
          {
              "role": "system",
              "content": [{"type": "text", "text": "You are a helpful text translator that translates text from hinglish to english"},]
          },
          {
              "role": "user",
              "content": [{"type": "text", "text": text},]
          },
      ],
  ]

  output1 = pipe(messages1, max_new_tokens=50)
  assistant_content = output1[0][0]['generated_text'][-1]['content']
  match = re.search(r'\*\*"(.+?)"\*\*', assistant_content)
  translated_text=match.group(1)
  return translated_text

translation("thik tha bas,kuch khas nai")

#sentiment analysis
def sentiment_analysis(text):
  messages2 = [
          [
              {
                  "role": "system",
                  "content": [{"type": "text", "text": "You are a helpful text classifier into positive,negative and neutral classes"},]
              },
              {
                  "role": "user",
                  "content": [{"type": "text", "text": text},]
              },
          ],
      ]
  output2 = pipe(messages2, max_new_tokens=1)
  return output2[0][0]['generated_text'][-1]['content']

texts = [
    "Oh great, another Monday. Just what I needed to make my life more exciting.",
    "Wow, your customer service is so fast—I only waited 2 hours on hold!",
    "What a fantastic idea to schedule a meeting at 7 AM on a weekend.",
    "The software crashed again? Awesome. I was getting bored anyway.",
    "Oh perfect, now the printer isn’t working too. My day is complete.",
    "Thanks for delivering my order two weeks late. Right on time!",
    "I just love it when everything goes wrong right before a deadline.",
    "Oh sure, because nothing says 'efficient' like reloading the same page ten times."
]

start=time.time()
ans=[]
for text in texts:
  ans.append(sentiment_analysis(text))
end=time.time()

total_time=end-start

total_time

gc.collect()

sentiment_analysis("The audio was not clear")

